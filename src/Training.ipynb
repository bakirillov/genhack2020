{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytorch_ranger\n",
    "from contr_loss import *\n",
    "from tensorlayer import *\n",
    "from preprocessing import *\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = dna2vecDataModule(\n",
    "    vector_path=\"../dna2vec/pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v\", \n",
    "    fasta_path=\"training_set.fasta\",\n",
    "    kmers=[3,4,5,6,7,8], batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorSiamese(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, order, input_dim, output_dim, rank_tucker=5):\n",
    "        super(TensorSiamese, self).__init__()\n",
    "        self.tensor = NeuralTensorLayer(\n",
    "            order, input_dim, output_dim, rank_tucker=rank_tucker\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        self.s = nn.Sigmoid()\n",
    "        self.loss = ContrastiveLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return(self.s(self.bn(self.tensor(x))))\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = pytorch_ranger.RangerQH(self.parameters())\n",
    "        return(optimizer)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        x1 = x[:,0:100]\n",
    "        x2 = x[:,100:]\n",
    "        left = self.forward(x1)\n",
    "        right = self.forward(x2)\n",
    "        loss = self.loss(left, right, y)+0.5*self.tensor.get_orthogonality_loss()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return(loss)\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        x1 = x[:,0:100]\n",
    "        x2 = x[:,100:]\n",
    "        left = self.forward(x1)\n",
    "        right = self.forward(x2)\n",
    "        loss = self.loss(left, right, y)+0.5*self.tensor.get_orthogonality_loss()\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return(loss)\n",
    "    \n",
    "    def predict(self, val_batch):\n",
    "        x, _ = val_batch\n",
    "        x1 = x[:,0:100]\n",
    "        x2 = x[:,100:]\n",
    "        left = self.forward(x1)\n",
    "        right = self.forward(x2)\n",
    "        return(F.pairwise_distance(left,right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakirillov/HDD/works/Hackathons/genhack2020/src/tensorlayer.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  initializer(self.bias)\n"
     ]
    }
   ],
   "source": [
    "model = TensorSiamese(3, 100, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=\"0\", max_epochs=100,\n",
    "    default_root_dir=\"../checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "  | Name   | Type              | Params\n",
      "---------------------------------------------\n",
      "0 | tensor | NeuralTensorLayer | 4 K   \n",
      "1 | bn     | BatchNorm1d       | 100   \n",
      "2 | s      | Sigmoid           | 0     \n",
      "3 | loss   | ContrastiveLoss   | 0     \n",
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113b404de9a4469a8de776a3d6313aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakirillov/anaconda3/envs/lapki/lib/python3.7/site-packages/pytorch_ranger/rangerqh.py:152: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1_adj).add_(1.0 - beta1_adj, d_p)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
